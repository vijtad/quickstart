{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efb1cda221944b082e041528c8c4daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "Cannot show widget. You probably want to rerun the code cell above (<i>Click in the code cell, and press Shift+Enter <kbd>⇧</kbd>+<kbd>↩</kbd></i>)."
      ],
      "text/plain": [
       "Cannot show ipywidgets in text"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this code is generated by the Domino Code Assist toolbar button\n",
    "import domino_code_assist as dca\n",
    "dca.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments (MLflow) Tutorial\n",
    "\n",
    "This `experiment.ipynb` Jupyter notebook shows an example of how you can use the Experiments feature to train and compare models.\n",
    "\n",
    "In this tutorial, you will:\n",
    "* train several support vector machine models to classify handwritten digits\n",
    "* create an experiment using MLflow\n",
    "* create runs within an experiment using MLflow\n",
    "* persist parameters, metrics, and artifacts that ensure reproducibility and enable visual comparison of models\n",
    "\n",
    "## Attribution\n",
    "* Some code is adapted from [sklearn's tutorial for \"Recognizing hand-written digits\"](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html)\n",
    "* Inspriation for the structure of the experiment and runs taken from [mlflow's sklearn_elasticnet_wine example](https://github.com/mlflow/mlflow/blob/master/examples/sklearn_elasticnet_wine/train.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License for code in this notebook: BSD 3 clause\n",
    "# import everything we'll need for the rest of the notebook\n",
    "import os\n",
    "from copy import copy\n",
    "from itertools import product\n",
    "import pprint\n",
    "import shutil\n",
    "import time\n",
    "from typing import Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn import datasets, metrics, svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experiment in MLflow\n",
    "\n",
    "# we'll make the name unique in the project by appending a timestamp so that you and other users can run this cell more than once.\n",
    "timestamp = time.time()\n",
    "username = os.environ['DOMINO_STARTING_USERNAME']\n",
    "experiment_name = f\"example-svm-digit-classifier-{username}-{timestamp}\"\n",
    "# below, we'll use the returned experiment_id in calls to mlflow.start_run() to add data to the experiment.\n",
    "experiment_id = mlflow.create_experiment(experiment_name)\n",
    "print(f\"Experiment id: {experiment_id}\")\n",
    "print(f\"Experiment name: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "\n",
    "# this dataset has handwritten roman numerals represented as 8x8 pixel grayscale images\n",
    "digits = datasets.load_digits()\n",
    "# flatten each 2-D array of grayscale values from shape (8, 8) into shape (64,)\n",
    "# data will have shape (n_samples = number of images, n_features = total number of pixels in each image)\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "# split the data into train and test subsets\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    data, digits.target, test_size=0.20, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that uses an SVM to classify the digits while recording relevant info as an MLflow run \n",
    "# within the given experiment.\n",
    "def create_run_svm_classify(\n",
    "    experiment_id: str,\n",
    "    train_x: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    test_x: np.ndarray,\n",
    "    test_y: np.ndarray,\n",
    "    random_seed: int,\n",
    "    svc_param_kwargs: Dict = None,\n",
    "    run_name: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Record an MLflow run for experiment_id.\n",
    "    Trains a Support Vector Machine classifier using train_x, train_y, and the given svm_param_kwargs.\n",
    "    Then, predicts using test_x and test_y and logs params, metrics, artifacts, and model to MLflow.\n",
    "\n",
    "    :param str experiment_id: id of the MLflow experiment in which to record the run\n",
    "    :param np.ndarray train_x: x values for the training data\n",
    "    :param np.ndarray train_y: y values for the training data\n",
    "    :param np.ndarray test_x: x values for the test data\n",
    "    :param np.ndarray test_y: y values for the test data\n",
    "    :param int random_seed: used to set the random seed for all random number generators in this run \n",
    "        (e.g. numpy seed, sklearn model random state, etc.)\n",
    "    :param Dict svc_param_kwargs: kwargs to use when creating the sklearn.svm.SVC (e.g. C, kernel, etc.)\n",
    "    :param str run_name: name for the run in MLflow. If None, MLflow will generate a random name\n",
    "    \"\"\"\n",
    "    if random_seed is None:\n",
    "        random_seed = 42\n",
    "    svc_param_kwargs = svc_param_kwargs or {}\n",
    "    svc_param_kwargs[\"random_state\"] = random_seed\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # passing experiment_id tells MLflow to associate the run data with the correct experiment.\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=run_name) as run:\n",
    "        if run_name is None:\n",
    "            run_name = run.info.run_name\n",
    "        pretty_params = pprint.pformat(svc_param_kwargs, width=1, indent=2)\n",
    "        print(\"******************************************\")\n",
    "        print(\"******************************************\")\n",
    "        print(f\"Starting run {run_name} in experiment {experiment_id} with SVC params:\")\n",
    "        print(f\"{pretty_params}\")\n",
    "\n",
    "        print(\"Initializing model...\")\n",
    "        classifier = svm.SVC(**svc_param_kwargs)\n",
    "\n",
    "        print(\"Training model...\")\n",
    "        classifier.fit(train_x, train_y)\n",
    "\n",
    "        print(\"Predicting using trained model...\")\n",
    "        predicted = classifier.predict(test_x)\n",
    "        prediction_report_str = metrics.classification_report(test_y, predicted, digits=3, output_dict=False)\n",
    "        prediction_report_dict = metrics.classification_report(test_y, predicted, output_dict=True)\n",
    "\n",
    "        # print some info about the run and also save as file for an MLflow artifact\n",
    "        print(\"Finished predictions.\")\n",
    "        run_overview = (\n",
    "            f\"Run: {run_name}\\n\"\n",
    "            f\"Random seed: {random_seed}\\n\"\n",
    "            \"Classifier type: sklearn.svm.SVC\\n\"\n",
    "            \"Specified classifier params:\\n\"\n",
    "            f\"{pretty_params}\"\n",
    "            \"\\n\"\n",
    "            \"Classification report:\\n\"\n",
    "            f\"{prediction_report_str}\\n\"\n",
    "        )\n",
    "        print(f\"{run_overview}\")\n",
    "        run_overview_file_name = \"run_overview.txt\"\n",
    "        with open(run_overview_file_name, \"w\") as f:\n",
    "            f.write(run_overview)\n",
    "\n",
    "        # visualize model performance and save visualization for an MLflow artifact\n",
    "        disp = metrics.ConfusionMatrixDisplay.from_predictions(test_y, predicted)\n",
    "        disp.figure_.suptitle(f\"Confusion Matrix - Run {run_name}\")\n",
    "        confusion_matrix_file_name = f\"confusion_matrix_run_{run_name}.png\"\n",
    "        plt.savefig(confusion_matrix_file_name)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Recording run params, metrics, and artifacts to MLflow...\")\n",
    "        # record notable sklearn model params and performance metrics.\n",
    "        # this enables visual comparison via the Experiments UI.\n",
    "        for param, val in svc_param_kwargs.items():\n",
    "            mlflow.log_param(param, val)\n",
    "        # record metrics for each individual digit as well as overall averages\n",
    "        for metric in (\"precision\", \"recall\", \"f1-score\"):\n",
    "            for digit in {str(num) for num in range(0, 10)}:\n",
    "                mlflow.log_metric(f\"{metric}_{digit}\", prediction_report_dict[digit][metric])\n",
    "            for avg_type in (\"macro\", \"weighted\"):\n",
    "                mlflow.log_metric(f\"{metric}_{avg_type}_avg\", prediction_report_dict[f\"{avg_type} avg\"][metric])\n",
    "        mlflow.log_metric(\"overall_accuracy\", prediction_report_dict[\"accuracy\"])\n",
    "\n",
    "        # record the data for reproducibility\n",
    "        data_dir_name = \"run_data\"\n",
    "        os.mkdir(data_dir_name)\n",
    "        for data, data_name in ((train_x, \"train_x\"), (train_y, \"train_y\"), (test_x, \"test_x\"), (test_y, \"test_y\")):\n",
    "            with open(os.path.join(data_dir_name, f\"{data_name}.csv\"), \"w\") as data_file:\n",
    "                np.savetxt(data_file, data, delimiter=\",\")\n",
    "        mlflow.log_artifact(data_dir_name)\n",
    "        shutil.rmtree(data_dir_name)\n",
    "\n",
    "        # record human-readable/interpretable overview and figures\n",
    "        mlflow.log_artifact(run_overview_file_name)\n",
    "        mlflow.log_artifact(confusion_matrix_file_name)\n",
    "\n",
    "        # record the trained sklearn model\n",
    "        mlflow.sklearn.log_model(classifier, \"model\")\n",
    "        print(\"Finishing recording.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a hyperparam sweep to find the best regularization and gamma for an SVC with a radial basis function kernel\n",
    "random_seed = 470\n",
    "regularizations = [0.1, 1.0, 10.0, 100.0]\n",
    "gammas = [0.001, 0.01, 0.1, 1, 10]\n",
    "for regularization, gamma in product(regularizations, gammas):\n",
    "    svc_param_kwargs = {\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"C\": regularization,\n",
    "        \"gamma\": gamma,\n",
    "    }\n",
    "    # each call creates a \"run\" in MLflow and records metrics/artifacts about that run\n",
    "    create_run_svm_classify(\n",
    "        experiment_id,\n",
    "        train_x,\n",
    "        train_y,\n",
    "        test_x,\n",
    "        test_y,\n",
    "        random_seed,\n",
    "        svc_param_kwargs=svc_param_kwargs,\n",
    "        run_name=f\"C_{regularization}_gamma_{gamma}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"You created your first experiment!\")\n",
    "print(f\"Go to the Experiments UI and click on the {experiment_name} experiment to compare runs.\")\n",
    "print(\"You can also explore and share run artifacts (e.g. overview and confusion matrix).\")"
   ]
  }
 ],
 "metadata": {
  "dca-init": true,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
